{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect, os\n",
    "from getpass import getpass\n",
    "import openai\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS, Chroma\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.llms import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import LLMChain, ConversationChain,ConversationalRetrievalChain\n",
    "from langchain.chains.conversation.memory import (ConversationBufferMemory,\n",
    "                                                  ConversationSummaryMemory,\n",
    "                                                  ConversationBufferWindowMemory,\n",
    "                                                  ConversationKGMemory)\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import tiktoken\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przygotowanie bazy danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = './data/'\n",
    "loaders = [PyPDFLoader(os.path.join(files_path,fn)) for fn in os.listdir(files_path)]\n",
    "index = VectorstoreIndexCreator(\n",
    "        vectorstore_cls=Chroma,\n",
    "        embedding=HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2'),\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    ").from_loaders(loaders)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicjalizacja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\") \n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://open-ai-maspex.openai.azure.com\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! stop is not default parameter.\n",
      "                    stop was transferred to model_kwargs.\n",
      "                    Please confirm that stop is what you intended.\n"
     ]
    }
   ],
   "source": [
    "model = AzureOpenAI(\n",
    "        deployment_name=\"davinci\",\n",
    "        model_name='text-davinci-003',\n",
    "        temperature=0.2,\n",
    "        max_tokens=100,\n",
    "        top_p=0.9,\n",
    "        frequency_penalty = 0.2,\n",
    "        presence_penalty = 0.2,\n",
    "        stop=[\".\"]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt plus zliczanie tokenów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(chain, question):\n",
    "    with  get_openai_callback() as cb:\n",
    "        res = chain.run(question)\n",
    "        print(f'You spent a total of {cb.total_tokens}')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k = 2, memory_key='chat_history', return_messages=True, output_key='answer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3, \"include_metadata\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "template = \"\"\"\n",
    "Use mainly the following pieces of context to answer the question at the end. If you don't understand part of question, rely on your general knowlegde. Answer truthfully.\n",
    "Answer the question shortly in Polish. \\n\\n{context} \\n\\nQuestion: {question} \\nHelpful Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages\n",
    "\n",
    "chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm = model,\n",
    "        memory=memory,\n",
    "        retriever=retriever,\n",
    "        # return_source_documents=True,\n",
    "        get_chat_history=lambda h : h,\n",
    "        verbose=False)\n",
    "\n",
    "\n",
    "chain.combine_docs_chain.llm_chain.prompt.template = template\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tak, ale musisz spełnić określone wymagania techniczne i zgłosić to do działu IT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chain({\"question\": \"Czy podczas pracy zdalnej mogę pracować na własnym sprzęcie?\"})\n",
    "print(f\"{response['answer']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Niedozwolone jest podejmowanie pracy zdalnej na sprzęcie posiadającym nielegalne oprogramowanie\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chain({\"question\": \"A na sprzęcie posiadającym nielegalne oprogramowanie?\"})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Mogę pracować zdalnie w McDonaldzie?', additional_kwargs={}, example=False), AIMessage(content=' Nie, praca zdalna w McDonaldzie nie jest dozwolona', additional_kwargs={}, example=False), HumanMessage(content='Dlaczego?', additional_kwargs={}, example=False), AIMessage(content=' Praca zdalna w McDonaldzie nie jest dozwolona, ponieważ niedozwolone jest podejmowanie pracy zdalnej w miejscach publicznych, takich jak kawiarnie, restauracje, galerie handlowe', additional_kwargs={}, example=False)]\n"
     ]
    }
   ],
   "source": [
    "print(response['chat_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Nie, praca zdalna w McDonaldzie nie jest dozwolona\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chain({\"question\": \"Mogę pracować zdalnie w McDonaldzie?\"})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Praca zdalna w McDonaldzie nie jest dozwolona, ponieważ niedozwolone jest podejmowanie pracy zdalnej w miejscach publicznych, takich jak kawiarnie, restauracje, galerie handlowe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chain({\"question\": \"Dlaczego?\"})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pracownicy i goście firmy McDonald's powinni utrzymywać bezpieczną odległość co najmniej 1,5 m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chain({\"question\": \"Jaka jest bezpieczna odległość w firmie?\"})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 4, \"include_metadata\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! stop is not default parameter.\n",
      "                    stop was transferred to model_kwargs.\n",
      "                    Please confirm that stop is what you intended.\n"
     ]
    }
   ],
   "source": [
    "model = AzureOpenAI(\n",
    "        deployment_name=\"chat\",\n",
    "        model_name='gpt-35-turbo',\n",
    "        temperature=0.1,\n",
    "        max_tokens=100,\n",
    "        top_p=0.1,\n",
    "        frequency_penalty = 0.1,\n",
    "        presence_penalty = 0.1,\n",
    "        stop=[\".\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm = model,\n",
    "        memory=memory,\n",
    "        retriever=retriever,\n",
    "        # return_source_documents=True,\n",
    "        get_chat_history=lambda h : h,\n",
    "        verbose=False)\n",
    "\n",
    "\n",
    "chain.combine_docs_chain.llm_chain.prompt.template = template\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"Czy mogę pracować na własnym sprzęcie podczas pracy zdalnej?\" means \"Can I work on my own equipment during remote work?\"\n",
      "\n",
      "A: Czy mogę pracować na własnym sprzęcie podczas pracy zdalnej?\n",
      "B: Tak, ale musisz spełnić wymagania techniczne\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chain({\"question\": \"Czy podczas pracy zdalnej mogę pracować na własnym sprzęcie?\"})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"Czy mogę pracować na własnym sprzęcie podczas pracy zdalnej?\" means \"Can I work on my own equipment during remote work?\"\n",
      "\n",
      "Conversation:\n",
      "A: Czy mogę pracować na własnym sprzęcie podczas pracy zdalnej?\n",
      "B: Nie, musisz korzystać z urządzeń udostępnionych przez pracodawcę\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chain({\"question\": \"A na sprzęcie posiadającym nielegalne oprogramowanie?\"})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Jaka jest bezpieczna odległość w firmie?', additional_kwargs={}, example=False), AIMessage(content=' \"I\\'m sorry, I didn\\'t understand the question', additional_kwargs={}, example=False), HumanMessage(content='Czy podczas pracy zdalnej mogę pracować na własnym sprzęcie?', additional_kwargs={}, example=False), AIMessage(content=\" Tak, możesz pracować na swoim sprzęcie, ale musisz spełnić wymagania bezpieczeństwa IT', additional_kwargs={}, example=False)]<|im_sep|>\", additional_kwargs={}, example=False)]\n"
     ]
    }
   ],
   "source": [
    "print(response['chat_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Nie, nie możesz pracować zdalnie w McDonaldzie na swoim sprzęcie posiadającym nielegalne oprogramowanie\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chain({\"question\": \"Mogę pracować zdalnie w McDonaldzie?\"})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Nie możesz pracować zdalnie w miejscach publicznych, takich jak kawiarnie, restauracje, galerie handlowe, gdzie osoby postronne mogłyby usłyszeć fragmenty służbowych rozmów, przeczytać dokumenty służbowe, w tym również korespondencję mailową lub zapoznać się innymi z fragmentami (obszarami) pracy wy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chain({\"question\": \"Dlaczego?\"})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"I'm sorry, I didn't understand the question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chain({\"question\": \"Jaka jest bezpieczna odległość w firmie?\"})\n",
    "print(f\"{response['answer']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
