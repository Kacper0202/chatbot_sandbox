{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://open-ai-maspex.openai.azure.com/\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "load_dotenv()\n",
    "# initialize the models\n",
    "model = AzureOpenAI(\n",
    "        deployment_name=\"davinci\",\n",
    "        model_name='text-davinci-003',\n",
    "        temperature=1\n",
    "    )\n",
    "embeddings = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "file_path = './data/book4.pdf'\n",
    "loader = PyPDFLoader(file_path)\n",
    "text = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(text)\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "vector_store = db.save_local('faiss_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_db = FAISS.load_local('faiss_index', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/n/nSources:\n",
      "\n",
      "Page: 312\n",
      "Text: 9.7. PRACTICE 297\n",
      "No. Those problems were probably always there, even in the other tools. But since Gibbs\n",
      "doesn’t use gradients, it doesn’t notice some issues that a Hamiltonian engine will. A culture\n",
      "has evolved in applied statistics of just running bad chains for a very long time—for millions of\n",
      "iterations—and then thinning aggressively, praying, and publishing. This must stop. [example of\n",
      "DOI:https://doi.org/10.1016/j.cub.2018.03.020 — 5 million samples, neff of 66!] Tools like Stan and\n",
      "other Hamiltonian engines are so important for reliable research precisely because they more diag-\n",
      "nostic criteria for the accuracy of the Monte Carlo approximation. Don’t resent the nagging.\n",
      "9.6. Summary\n",
      "This chapter has been an informal introduction to Markov chain Monte Carlo (MCMC)\n",
      "estimation. The goal has been to introduce the purpose and approach MCMC algorithms.\n",
      "The major algorithms introduced were the Metropolis, Gibbs sampling, and Hamiltonian\n",
      "Monte Carlo algorithms. Each has its advantages and disadvantages. A function in the re-\n",
      "thinking package, map2stan ,wasintroducedthatusestheStan(mc-stan.org)Hamiltonian\n",
      "Monte Carlo engine to fit models as they are defined in this book. General advice about di-\n",
      "agnosing poor MCMC fits was introduced by the use of a couple of pathological examples.\n",
      "9.7. Practice\n",
      "Easy.\n",
      "8E1.Which of the following is a requirement of the simple Metropolis algorithm?\n",
      "(1)The parameters must be discrete.\n",
      "(2)The likelihood function must be Gaussian.\n",
      "(3)The proposal distribution must be symmetric.\n",
      "8E2.Gibbs sampling is more efficient than the Metropolis algorithm. How does it achieve this extra\n",
      "efficiency? Are there any limitations to the Gibbs sampling strategy?\n",
      "8E3.Which sort of parameters can Hamiltonian Monte Carlo not handle? Can you explain why?\n",
      "8E4.Explain the difference between the effective number of samples, n_effas calculated by Stan,\n",
      "and the actual number of samples.\n",
      "8E5.Which value should Rhatapproach, when a chain is sampling the posterior distribution cor-\n",
      "rectly?\n",
      "8E6.Sketch a good trace plot for a Markov chain, one that is effectively sampling from the posterior\n",
      "distribution. What is good about its shape? Then sketch a trace plot for a malfunctioning Markov\n",
      "chain. What about its shape indicates malfunction?\n",
      "Medium.\n",
      "8M1.Re-estimatetheterrainruggednessmodelfromthechapter,butnowusingauniformpriorand\n",
      "an exponential prior for the standard deviation, sigma. The uniform prior should be dunif(0,10)\n",
      "and the exponential should be dexp(1) . Do the different priors have any detectible influence on the\n",
      "posterior distribution?\n",
      "8M2.The Cauchy and exponential priors from the terrain ruggedness model are very weak. They\n",
      "can be made more informative by reducing their scale. Compare the dcauchy anddexppriors for\n",
      "progressivelysmallervaluesofthescalingparameter. Asthesepriorsbecomestronger,howdoeseach\n",
      "influence the posterior distribution?...\n",
      "\n",
      "Page: 298\n",
      "Text: 9.4. EASY HMC: ULAM 283\n",
      "a[2] 1.05 0.01 1.03 1.07 873 1\n",
      "These estimates are very similar to the quadratic approximation. But note that there are two\n",
      "new columns, n_effandRhat. These columns provide MCMC diagnostic criteria, to help\n",
      "you tell how well the sampling worked. We’ll discuss them in detail later in the chapter. For\n",
      "now, it’s enough to know that n_effis a crude estimate of the number of independent sam-\n",
      "ples you managed to get. Rhatis a complicated estimate of the convergence of the Markov\n",
      "chains to the target distribution. It should approach 1.00 from above, when all is well.\n",
      "9.4.3. Samplingagain,inparallel. TheexamplesofarisaveryeasyproblemforMCMC.So\n",
      "eventhedefault1000samplesisenoughforaccurateinference. Infact,asfewas200effective\n",
      "samples is usually plenty for a good approximation of the posterior. But we also want to run\n",
      "multiple chains, for reasons we’ll discuss in more depth in the next sections. There will be\n",
      "specific advice in Section 9.5(page288).\n",
      "For now, it’s worth noting that you can easily parallelize those chains, as well. They\n",
      "can all run at the same time, instead of in sequence. So as long as your computer has four\n",
      "cores (it probably does), it won’t take longer to run four chains than one chain. To run four\n",
      "independentMarkovchainsforthemodelabove,andtodistributethemacrossseparatecores\n",
      "in your computer, just increase the number of chains and add a coresargument:\n",
      "R code\n",
      "9.14m9.1 <- ulam(\n",
      "alist(\n",
      "log_gdp_std ~ dnorm( mu , sigma ) ,\n",
      "mu <- a[cid] + b[cid]*( rugged_std - 0.215 ) ,\n",
      "a[cid] ~ dnorm( 1 , 0.1 ) ,\n",
      "b[cid] ~ dnorm( 0 , 0.3 ) ,\n",
      "sigma ~ dexp( 1 )\n",
      ") ,\n",
      "data=dat_slim , chains=4 , cores=4 , iter=1000 )\n",
      "There are a bunch of optional arguments that allow us to tune and customize the process.\n",
      "We’ll bring them up as they are needed. For now, keep in mind that showwill remind you of\n",
      "the model formula and also how long each chain took to run:\n",
      "R code\n",
      "9.15show( m9.1 )\n",
      "Hamiltonian Monte Carlo approximation\n",
      "2000 samples from 4 chains\n",
      "Sampling durations (seconds):\n",
      "warmup sample total\n",
      "chain:1 0.12 0.08 0.20\n",
      "chain:2 0.12 0.08 0.19\n",
      "chain:3 0.12 0.08 0.20\n",
      "chain:4 0.12 0.08 0.20\n",
      "Formula:\n",
      "log_gdp_std ~ dnorm(mu, sigma)\n",
      "mu <- a[cid] + b[cid] * (rugged_std - 0.215)\n",
      "a[cid] ~ dnorm(1, 0.1)...\n",
      "\n",
      "Page: 284\n",
      "Text: 9.2. METROPOLIS, GIBBS, AND SADNESS 269\n",
      "9.2. Metropolis, Gibbs, and Sadness\n",
      "The precise algorithm King Markov used is a special case of the general Metropolis\n",
      "algorithm from the real world.133And this algorithm is an example of Markov chain\n",
      "Monte Carlo. In real applications, the goal is of course not to help an autocrat schedule\n",
      "his journeys, but instead to draw samples from an unknown and usually complex target\n",
      "distribution, like a posterior probability distribution.\n",
      "\u000fThe “islands” in our objective are parameter values, and they need not be discrete,\n",
      "but can instead take on a continuous range of values as usual.\n",
      "\u000fThe “population sizes” in our objective are the posterior probabilities at each pa-\n",
      "rameter value.\n",
      "\u000fThe “weeks” in our objective are samples taken from the joint posterior of the pa-\n",
      "rameters in the model.\n",
      "Provided the way we choose our proposed parameter values at each step is symmetric—so\n",
      "thatthereisanequalchanceofproposingfromAtoBandfromBtoA—thentheMetropolis\n",
      "algorithmwilleventuallygiveusacollectionofsamplesfromthejointposterior. Wecanthen\n",
      "use these samples just like all the samples you’ve already used in this book.\n",
      "The Metropolis algorithm is the grandparent of several different strategies for getting\n",
      "samples from unknown posterior distributions. In the remainder of this section, I briefly\n",
      "explain the concept behind Gibbs sampling. Gibbs sampling is much better than plain Me-\n",
      "tropolis, and it continues to be common in applied Bayesian statistics. But it is rapidly being\n",
      "replaced by other algorithms.\n",
      "9.2.1. Gibbssampling. TheMetropolisalgorithmworkswhenevertheprobabilityofpropos-\n",
      "ing a jump to B from A is equal to the probability of proposing A from B, when the pro-\n",
      "posal distribution is symmetric. There is a more general method, known as Metropolis-\n",
      "Hastings,134that allows asymmetric proposals. This would mean, in the context of King\n",
      "Markov’s fable, that the King’s coin were biased to lead him clockwise on average.\n",
      "Why would we want an algorithm that allows asymmetric proposals? One reason is that\n",
      "it makes it easier to handle parameters, like standard deviations, that have boundaries at\n",
      "zero. A better reason, however, is that it allows us to generate savvy proposals that explore\n",
      "the posterior distribution more efficiently. By “more efficiently,” I mean that we can acquire\n",
      "an equally good image of the posterior distribution in fewer steps.\n",
      "Themost commonway to generatesavvy proposalsis a techniqueknown as Gibbssam-\n",
      "pling.135Gibbs sampling is a variant of the Metropolis-Hastings algorithm that uses clever\n",
      "proposals and is therefore more efficient. By “efficient,” I mean that you can get a good\n",
      "estimate of the posterior from Gibbs sampling with many fewer samples than a comparable\n",
      "Metropolisapproach. Theimprovementarisesfrom adaptive proposals inwhichthedistribu-\n",
      "tion of proposed parameter values adjusts itself intelligently, depending upon the parameter\n",
      "values at the moment.\n",
      "How Gibbs sampling computes these adaptive proposals depends upon using particu-\n",
      "lar combinations of prior distributions and likelihoods known as conjugate pairs . Conjugate\n",
      "pairs haveanalytical solutions fortheposterior distributionofan individual parameter. And\n",
      "these solutions are what allow Gibbs sampling to make smart jumps around the joint poste-\n",
      "rior distribution of all parameters.\n",
      "In practice, Gibbs sampling can be very efficient, and it’s the basis of popular Bayesian\n",
      "model fitting software like BUGS(Bayesian inference Using Gibbs Sampling) and JAGS(Just...\n",
      "\n",
      "Page: 386\n",
      "Text: 11.5. PRACTICE 371\n",
      "10H1. Usemapto construct a quadratic approximate posterior distribution for the chimpanzee\n",
      "model that includes a unique intercept for each actor, m10.4(page??). Compare the quadratic ap-\n",
      "proximation to the posterior distribution produced instead from MCMC. Can you explain both the\n",
      "differences and the similarities between the approximate and the MCMC distributions?\n",
      "10H2. Use WAIC to compare the chimpanzee model that includes a unique intercept for each actor,\n",
      "m10.4(page??), to the simpler models fit in the same section.\n",
      "10H3. The data contained in library(MASS);data(eagles) are records of salmon pirating at-\n",
      "tempts by Bald Eagles in Washington State. See ?eagles for details. While one eagle feeds, some-\n",
      "timesanotherwillswoopinandtrytostealthesalmonfromit. Callthefeedingeaglethe“victim”and\n",
      "the thief the “pirate.” Use the available data to build a binomial GLM of successful pirating attempts.\n",
      "(a) Consider the following model:\n",
      "yi\u0018Binomial (ni;pi)\n",
      "logpi\n",
      "1\u0000pi=\u000b+\fPPi+\fVVi+\fAAi\n",
      "\u000b\u0018Normal (0;10)\n",
      "\fP\u0018Normal (0;5)\n",
      "\fV\u0018Normal (0;5)\n",
      "\fA\u0018Normal (0;5)\n",
      "whereyis the number of successful attempts, nis the total number of attempts, Pis a dummy variable\n",
      "indicating whether or not the pirate had large body size, Vis a dummy variable indicating whether\n",
      "or not the victim had large body size, and finally Ais a dummy variable indicating whether or not the\n",
      "pirate was an adult. Fit the model above to the eagles data, using both mapandmap2stan . Is the\n",
      "quadratic approximation okay?\n",
      "(b) Now interpret the estimates. If the quadratic approximation turned out okay, then it’s okay to\n",
      "use the mapestimates. Otherwise stick to map2stan estimates. Then plot the posterior predictions.\n",
      "Computeanddisplayboth(1)thepredicted probability ofsuccessandits89%intervalforeachrow( i)\n",
      "inthedata,aswellas(2)thepredictedsuccess countandits89%interval. Whatdifferentinformation\n",
      "does each type of posterior prediction provide?\n",
      "(c) Now try to improve the model. Consider an interaction between the pirate’s size and age\n",
      "(immature or adult). Compare this model to the previous one, using WAIC. Interpret.\n",
      "10H4. The data contained in data(salamanders) are counts of salamanders ( Plethodon elongatus )\n",
      "from 47 different 49-m2plots in northern California.166The column SALAMAN is the count in each\n",
      "plot, and the columns PCTCOVER andFORESTAGE are percent of ground cover and age of trees in the\n",
      "plot, respectively. You will model SALAMAN as a Poisson variable.\n",
      "(a) Model the relationship between density and percent cover, using a log-link (same as the ex-\n",
      "ampleinthebookandlecture). Useweaklyinformativepriorsofyourchoosing. Checkthequadratic\n",
      "approximation again, by comparing maptomap2stan . Then plot the expected counts and their 89%\n",
      "interval against percent cover. In which ways does the model do a good job? In which ways does it\n",
      "do a bad job?\n",
      "(b) Can you improve the model by using the other predictor, FORESTAGE ? Try any models you\n",
      "think useful. Can you explain why FORESTAGE helps or does not help with prediction?...\n",
      "\n",
      "Answer:  MCMC stands for Markov Chain Monte Carlo. It is a technique used in Bayesian statistics to generate samples from an unknown and usually complex target distribution, like a posterior probability distribution.\n",
      "\n",
      "/n/nSources:\n",
      "\n",
      "Page: 312\n",
      "Text: 9.7. PRACTICE 297\n",
      "No. Those problems were probably always there, even in the other tools. But since Gibbs\n",
      "doesn’t use gradients, it doesn’t notice some issues that a Hamiltonian engine will. A culture\n",
      "has evolved in applied statistics of just running bad chains for a very long time—for millions of\n",
      "iterations—and then thinning aggressively, praying, and publishing. This must stop. [example of\n",
      "DOI:https://doi.org/10.1016/j.cub.2018.03.020 — 5 million samples, neff of 66!] Tools like Stan and\n",
      "other Hamiltonian engines are so important for reliable research precisely because they more diag-\n",
      "nostic criteria for the accuracy of the Monte Carlo approximation. Don’t resent the nagging.\n",
      "9.6. Summary\n",
      "This chapter has been an informal introduction to Markov chain Monte Carlo (MCMC)\n",
      "estimation. The goal has been to introduce the purpose and approach MCMC algorithms.\n",
      "The major algorithms introduced were the Metropolis, Gibbs sampling, and Hamiltonian\n",
      "Monte Carlo algorithms. Each has its advantages and disadvantages. A function in the re-\n",
      "thinking package, map2stan ,wasintroducedthatusestheStan(mc-stan.org)Hamiltonian\n",
      "Monte Carlo engine to fit models as they are defined in this book. General advice about di-\n",
      "agnosing poor MCMC fits was introduced by the use of a couple of pathological examples.\n",
      "9.7. Practice\n",
      "Easy.\n",
      "8E1.Which of the following is a requirement of the simple Metropolis algorithm?\n",
      "(1)The parameters must be discrete.\n",
      "(2)The likelihood function must be Gaussian.\n",
      "(3)The proposal distribution must be symmetric.\n",
      "8E2.Gibbs sampling is more efficient than the Metropolis algorithm. How does it achieve this extra\n",
      "efficiency? Are there any limitations to the Gibbs sampling strategy?\n",
      "8E3.Which sort of parameters can Hamiltonian Monte Carlo not handle? Can you explain why?\n",
      "8E4.Explain the difference between the effective number of samples, n_effas calculated by Stan,\n",
      "and the actual number of samples.\n",
      "8E5.Which value should Rhatapproach, when a chain is sampling the posterior distribution cor-\n",
      "rectly?\n",
      "8E6.Sketch a good trace plot for a Markov chain, one that is effectively sampling from the posterior\n",
      "distribution. What is good about its shape? Then sketch a trace plot for a malfunctioning Markov\n",
      "chain. What about its shape indicates malfunction?\n",
      "Medium.\n",
      "8M1.Re-estimatetheterrainruggednessmodelfromthechapter,butnowusingauniformpriorand\n",
      "an exponential prior for the standard deviation, sigma. The uniform prior should be dunif(0,10)\n",
      "and the exponential should be dexp(1) . Do the different priors have any detectible influence on the\n",
      "posterior distribution?\n",
      "8M2.The Cauchy and exponential priors from the terrain ruggedness model are very weak. They\n",
      "can be made more informative by reducing their scale. Compare the dcauchy anddexppriors for\n",
      "progressivelysmallervaluesofthescalingparameter. Asthesepriorsbecomestronger,howdoeseach\n",
      "influence the posterior distribution?...\n",
      "\n",
      "Page: 284\n",
      "Text: 9.2. METROPOLIS, GIBBS, AND SADNESS 269\n",
      "9.2. Metropolis, Gibbs, and Sadness\n",
      "The precise algorithm King Markov used is a special case of the general Metropolis\n",
      "algorithm from the real world.133And this algorithm is an example of Markov chain\n",
      "Monte Carlo. In real applications, the goal is of course not to help an autocrat schedule\n",
      "his journeys, but instead to draw samples from an unknown and usually complex target\n",
      "distribution, like a posterior probability distribution.\n",
      "\u000fThe “islands” in our objective are parameter values, and they need not be discrete,\n",
      "but can instead take on a continuous range of values as usual.\n",
      "\u000fThe “population sizes” in our objective are the posterior probabilities at each pa-\n",
      "rameter value.\n",
      "\u000fThe “weeks” in our objective are samples taken from the joint posterior of the pa-\n",
      "rameters in the model.\n",
      "Provided the way we choose our proposed parameter values at each step is symmetric—so\n",
      "thatthereisanequalchanceofproposingfromAtoBandfromBtoA—thentheMetropolis\n",
      "algorithmwilleventuallygiveusacollectionofsamplesfromthejointposterior. Wecanthen\n",
      "use these samples just like all the samples you’ve already used in this book.\n",
      "The Metropolis algorithm is the grandparent of several different strategies for getting\n",
      "samples from unknown posterior distributions. In the remainder of this section, I briefly\n",
      "explain the concept behind Gibbs sampling. Gibbs sampling is much better than plain Me-\n",
      "tropolis, and it continues to be common in applied Bayesian statistics. But it is rapidly being\n",
      "replaced by other algorithms.\n",
      "9.2.1. Gibbssampling. TheMetropolisalgorithmworkswhenevertheprobabilityofpropos-\n",
      "ing a jump to B from A is equal to the probability of proposing A from B, when the pro-\n",
      "posal distribution is symmetric. There is a more general method, known as Metropolis-\n",
      "Hastings,134that allows asymmetric proposals. This would mean, in the context of King\n",
      "Markov’s fable, that the King’s coin were biased to lead him clockwise on average.\n",
      "Why would we want an algorithm that allows asymmetric proposals? One reason is that\n",
      "it makes it easier to handle parameters, like standard deviations, that have boundaries at\n",
      "zero. A better reason, however, is that it allows us to generate savvy proposals that explore\n",
      "the posterior distribution more efficiently. By “more efficiently,” I mean that we can acquire\n",
      "an equally good image of the posterior distribution in fewer steps.\n",
      "Themost commonway to generatesavvy proposalsis a techniqueknown as Gibbssam-\n",
      "pling.135Gibbs sampling is a variant of the Metropolis-Hastings algorithm that uses clever\n",
      "proposals and is therefore more efficient. By “efficient,” I mean that you can get a good\n",
      "estimate of the posterior from Gibbs sampling with many fewer samples than a comparable\n",
      "Metropolisapproach. Theimprovementarisesfrom adaptive proposals inwhichthedistribu-\n",
      "tion of proposed parameter values adjusts itself intelligently, depending upon the parameter\n",
      "values at the moment.\n",
      "How Gibbs sampling computes these adaptive proposals depends upon using particu-\n",
      "lar combinations of prior distributions and likelihoods known as conjugate pairs . Conjugate\n",
      "pairs haveanalytical solutions fortheposterior distributionofan individual parameter. And\n",
      "these solutions are what allow Gibbs sampling to make smart jumps around the joint poste-\n",
      "rior distribution of all parameters.\n",
      "In practice, Gibbs sampling can be very efficient, and it’s the basis of popular Bayesian\n",
      "model fitting software like BUGS(Bayesian inference Using Gibbs Sampling) and JAGS(Just...\n",
      "\n",
      "Page: 298\n",
      "Text: 9.4. EASY HMC: ULAM 283\n",
      "a[2] 1.05 0.01 1.03 1.07 873 1\n",
      "These estimates are very similar to the quadratic approximation. But note that there are two\n",
      "new columns, n_effandRhat. These columns provide MCMC diagnostic criteria, to help\n",
      "you tell how well the sampling worked. We’ll discuss them in detail later in the chapter. For\n",
      "now, it’s enough to know that n_effis a crude estimate of the number of independent sam-\n",
      "ples you managed to get. Rhatis a complicated estimate of the convergence of the Markov\n",
      "chains to the target distribution. It should approach 1.00 from above, when all is well.\n",
      "9.4.3. Samplingagain,inparallel. TheexamplesofarisaveryeasyproblemforMCMC.So\n",
      "eventhedefault1000samplesisenoughforaccurateinference. Infact,asfewas200effective\n",
      "samples is usually plenty for a good approximation of the posterior. But we also want to run\n",
      "multiple chains, for reasons we’ll discuss in more depth in the next sections. There will be\n",
      "specific advice in Section 9.5(page288).\n",
      "For now, it’s worth noting that you can easily parallelize those chains, as well. They\n",
      "can all run at the same time, instead of in sequence. So as long as your computer has four\n",
      "cores (it probably does), it won’t take longer to run four chains than one chain. To run four\n",
      "independentMarkovchainsforthemodelabove,andtodistributethemacrossseparatecores\n",
      "in your computer, just increase the number of chains and add a coresargument:\n",
      "R code\n",
      "9.14m9.1 <- ulam(\n",
      "alist(\n",
      "log_gdp_std ~ dnorm( mu , sigma ) ,\n",
      "mu <- a[cid] + b[cid]*( rugged_std - 0.215 ) ,\n",
      "a[cid] ~ dnorm( 1 , 0.1 ) ,\n",
      "b[cid] ~ dnorm( 0 , 0.3 ) ,\n",
      "sigma ~ dexp( 1 )\n",
      ") ,\n",
      "data=dat_slim , chains=4 , cores=4 , iter=1000 )\n",
      "There are a bunch of optional arguments that allow us to tune and customize the process.\n",
      "We’ll bring them up as they are needed. For now, keep in mind that showwill remind you of\n",
      "the model formula and also how long each chain took to run:\n",
      "R code\n",
      "9.15show( m9.1 )\n",
      "Hamiltonian Monte Carlo approximation\n",
      "2000 samples from 4 chains\n",
      "Sampling durations (seconds):\n",
      "warmup sample total\n",
      "chain:1 0.12 0.08 0.20\n",
      "chain:2 0.12 0.08 0.19\n",
      "chain:3 0.12 0.08 0.20\n",
      "chain:4 0.12 0.08 0.20\n",
      "Formula:\n",
      "log_gdp_std ~ dnorm(mu, sigma)\n",
      "mu <- a[cid] + b[cid] * (rugged_std - 0.215)\n",
      "a[cid] ~ dnorm(1, 0.1)...\n",
      "\n",
      "Page: 281\n",
      "Text: 266 9. MARKOV CHAIN MONTE CARLO\n",
      "Figure 9.1. Good King Markov’s island king-\n",
      "dom. Each of the 10 islands has a population\n",
      "proportional to its number, 1 through 10. The\n",
      "King’s goal is to visit each island, in the long\n",
      "run, in proportion to its population size. This\n",
      "can be accomplished by the Metropolis algo-\n",
      "rithm.\n",
      "Rethinking: Stan was a man. The Stan programming language is not an abbreviation or acronym.\n",
      "Rather, it is named after Stanislaw Ulam (1909–1984). Ulam is credited as one of the inventors of\n",
      "Markov chain Monte Carlo. Together with Ed Teller, Ulam applied it to designing fusion bombs. But\n",
      "he and others soon applied the general Monte Carlo method to diverse problems of less monstrous\n",
      "nature. Ulam made important contributions in pure mathematics, chaos theory, and molecular and\n",
      "theoretical biology, as well.\n",
      "9.1. Good King Markov and His island kingdom\n",
      "For the moment, forget about posterior densities and MCMC. Consider instead the tale\n",
      "of Good King Markov.132King Markov was a benevolent autocrat of an island kingdom,\n",
      "a circular archipelago, with 10 islands. Each island was neighbored by two others, and the\n",
      "entire archipelago formed a ring. The islands were of different sizes, and so had different\n",
      "sized populations living on them. The second island was about twice as populous as the first,\n",
      "the third about three times as populous as the first, and so on, up to the largest island, which\n",
      "was 10 times as populous as the smallest. The good king’s island kingdom is displayed in\n",
      "Figure 9.1, with the islands numbered by their relative population sizes.\n",
      "The Good King was an autocrat, but he did have a number of obligations to His people.\n",
      "Amongtheseobligations, KingMarkovagreedtovisiteachislandinHiskingdomfromtime\n",
      "to time. Since the people love their king, each island would prefer that he visit them more\n",
      "often. And so everyone agreed that the king should visit each island in proportion to its\n",
      "population size, visiting the largest island 10 times as often as the smallest, for example.\n",
      "The Good King Markov, however, wasn’t one for schedules or bookkeeping, and so he\n",
      "wantedawaytofulfillhisobligationwithoutplanninghistravelsmonthsaheadoftime. Also,\n",
      "sincethearchipelagowasaring, theKinginsistedthatheonlymoveamongadjacentislands,\n",
      "to minimize time spent on the water—like many citizens of his kingdom, the king believes\n",
      "there are sea monsters in the middle of the archipelago.\n",
      "Theking’sadvisor,aMrMetropolis,engineeredacleversolutiontothesedemands. We’ll\n",
      "call this solution the Metropolis algorithm . Here’s how it works.\n",
      "(1)Wherever the King is, each week he decides between staying put for another week\n",
      "or moving to one of the two adjacent islands. To decide his next move, he flips a\n",
      "coin....\n",
      "\n",
      "Answer:  Markov Chain Monte Carlo\n",
      "\n",
      "/n/nSources:\n",
      "\n",
      "Page: 312\n",
      "Text: 9.7. PRACTICE 297\n",
      "No. Those problems were probably always there, even in the other tools. But since Gibbs\n",
      "doesn’t use gradients, it doesn’t notice some issues that a Hamiltonian engine will. A culture\n",
      "has evolved in applied statistics of just running bad chains for a very long time—for millions of\n",
      "iterations—and then thinning aggressively, praying, and publishing. This must stop. [example of\n",
      "DOI:https://doi.org/10.1016/j.cub.2018.03.020 — 5 million samples, neff of 66!] Tools like Stan and\n",
      "other Hamiltonian engines are so important for reliable research precisely because they more diag-\n",
      "nostic criteria for the accuracy of the Monte Carlo approximation. Don’t resent the nagging.\n",
      "9.6. Summary\n",
      "This chapter has been an informal introduction to Markov chain Monte Carlo (MCMC)\n",
      "estimation. The goal has been to introduce the purpose and approach MCMC algorithms.\n",
      "The major algorithms introduced were the Metropolis, Gibbs sampling, and Hamiltonian\n",
      "Monte Carlo algorithms. Each has its advantages and disadvantages. A function in the re-\n",
      "thinking package, map2stan ,wasintroducedthatusestheStan(mc-stan.org)Hamiltonian\n",
      "Monte Carlo engine to fit models as they are defined in this book. General advice about di-\n",
      "agnosing poor MCMC fits was introduced by the use of a couple of pathological examples.\n",
      "9.7. Practice\n",
      "Easy.\n",
      "8E1.Which of the following is a requirement of the simple Metropolis algorithm?\n",
      "(1)The parameters must be discrete.\n",
      "(2)The likelihood function must be Gaussian.\n",
      "(3)The proposal distribution must be symmetric.\n",
      "8E2.Gibbs sampling is more efficient than the Metropolis algorithm. How does it achieve this extra\n",
      "efficiency? Are there any limitations to the Gibbs sampling strategy?\n",
      "8E3.Which sort of parameters can Hamiltonian Monte Carlo not handle? Can you explain why?\n",
      "8E4.Explain the difference between the effective number of samples, n_effas calculated by Stan,\n",
      "and the actual number of samples.\n",
      "8E5.Which value should Rhatapproach, when a chain is sampling the posterior distribution cor-\n",
      "rectly?\n",
      "8E6.Sketch a good trace plot for a Markov chain, one that is effectively sampling from the posterior\n",
      "distribution. What is good about its shape? Then sketch a trace plot for a malfunctioning Markov\n",
      "chain. What about its shape indicates malfunction?\n",
      "Medium.\n",
      "8M1.Re-estimatetheterrainruggednessmodelfromthechapter,butnowusingauniformpriorand\n",
      "an exponential prior for the standard deviation, sigma. The uniform prior should be dunif(0,10)\n",
      "and the exponential should be dexp(1) . Do the different priors have any detectible influence on the\n",
      "posterior distribution?\n",
      "8M2.The Cauchy and exponential priors from the terrain ruggedness model are very weak. They\n",
      "can be made more informative by reducing their scale. Compare the dcauchy anddexppriors for\n",
      "progressivelysmallervaluesofthescalingparameter. Asthesepriorsbecomestronger,howdoeseach\n",
      "influence the posterior distribution?...\n",
      "\n",
      "Page: 284\n",
      "Text: 9.2. METROPOLIS, GIBBS, AND SADNESS 269\n",
      "9.2. Metropolis, Gibbs, and Sadness\n",
      "The precise algorithm King Markov used is a special case of the general Metropolis\n",
      "algorithm from the real world.133And this algorithm is an example of Markov chain\n",
      "Monte Carlo. In real applications, the goal is of course not to help an autocrat schedule\n",
      "his journeys, but instead to draw samples from an unknown and usually complex target\n",
      "distribution, like a posterior probability distribution.\n",
      "\u000fThe “islands” in our objective are parameter values, and they need not be discrete,\n",
      "but can instead take on a continuous range of values as usual.\n",
      "\u000fThe “population sizes” in our objective are the posterior probabilities at each pa-\n",
      "rameter value.\n",
      "\u000fThe “weeks” in our objective are samples taken from the joint posterior of the pa-\n",
      "rameters in the model.\n",
      "Provided the way we choose our proposed parameter values at each step is symmetric—so\n",
      "thatthereisanequalchanceofproposingfromAtoBandfromBtoA—thentheMetropolis\n",
      "algorithmwilleventuallygiveusacollectionofsamplesfromthejointposterior. Wecanthen\n",
      "use these samples just like all the samples you’ve already used in this book.\n",
      "The Metropolis algorithm is the grandparent of several different strategies for getting\n",
      "samples from unknown posterior distributions. In the remainder of this section, I briefly\n",
      "explain the concept behind Gibbs sampling. Gibbs sampling is much better than plain Me-\n",
      "tropolis, and it continues to be common in applied Bayesian statistics. But it is rapidly being\n",
      "replaced by other algorithms.\n",
      "9.2.1. Gibbssampling. TheMetropolisalgorithmworkswhenevertheprobabilityofpropos-\n",
      "ing a jump to B from A is equal to the probability of proposing A from B, when the pro-\n",
      "posal distribution is symmetric. There is a more general method, known as Metropolis-\n",
      "Hastings,134that allows asymmetric proposals. This would mean, in the context of King\n",
      "Markov’s fable, that the King’s coin were biased to lead him clockwise on average.\n",
      "Why would we want an algorithm that allows asymmetric proposals? One reason is that\n",
      "it makes it easier to handle parameters, like standard deviations, that have boundaries at\n",
      "zero. A better reason, however, is that it allows us to generate savvy proposals that explore\n",
      "the posterior distribution more efficiently. By “more efficiently,” I mean that we can acquire\n",
      "an equally good image of the posterior distribution in fewer steps.\n",
      "Themost commonway to generatesavvy proposalsis a techniqueknown as Gibbssam-\n",
      "pling.135Gibbs sampling is a variant of the Metropolis-Hastings algorithm that uses clever\n",
      "proposals and is therefore more efficient. By “efficient,” I mean that you can get a good\n",
      "estimate of the posterior from Gibbs sampling with many fewer samples than a comparable\n",
      "Metropolisapproach. Theimprovementarisesfrom adaptive proposals inwhichthedistribu-\n",
      "tion of proposed parameter values adjusts itself intelligently, depending upon the parameter\n",
      "values at the moment.\n",
      "How Gibbs sampling computes these adaptive proposals depends upon using particu-\n",
      "lar combinations of prior distributions and likelihoods known as conjugate pairs . Conjugate\n",
      "pairs haveanalytical solutions fortheposterior distributionofan individual parameter. And\n",
      "these solutions are what allow Gibbs sampling to make smart jumps around the joint poste-\n",
      "rior distribution of all parameters.\n",
      "In practice, Gibbs sampling can be very efficient, and it’s the basis of popular Bayesian\n",
      "model fitting software like BUGS(Bayesian inference Using Gibbs Sampling) and JAGS(Just...\n",
      "\n",
      "Page: 305\n",
      "Text: 290 9. MARKOV CHAIN MONTE CARLO\n",
      "optional coresargument lets you distribute the chains across different processors, so they\n",
      "can run simultaneously, rather than sequentially. All of the non-warmup samples from each\n",
      "chain will be automatically combined in the resulting inferences.\n",
      "So the question naturally arises: How many chains do we need? There are three answers\n",
      "to this question. First, when debugging a model, use a single chain. Then when deciding\n",
      "whether the chains are valid, you need more than one chain. Third, when you begin the\n",
      "final run that you’ll make inferences from, you only really need one chain. But using more\n",
      "than one chain is fine, as well. It just doesn’t matter, once you’re sure it’s working. I’ll briefly\n",
      "explain these answers.\n",
      "The first time you try to sample from a chain, you might not be sure whether the chain\n",
      "is working right. So of course you will check the trace plot. Having more than one chain\n",
      "during these checks helps to make sure that the Markov chains are all converging to the\n",
      "same distribution. Sometimes, individual chains look like they’ve settled down to a stable\n",
      "distribution, but if you run the chain again, it might settle down to a different distribution.\n",
      "When you run multiple Markov chains, and see that all of them end up in the same region\n",
      "of parameter space, it provides a check that the machine is working correctly. Using 3 or 4\n",
      "chains is conventional, and quite often more than enough to reassure us that the sampling is\n",
      "working properly.\n",
      "But once you’ve verified that the sampling is working well, and you have a good idea\n",
      "of how many warmup samples you need, it’s perfectly safe to just run one long chain. For\n",
      "example, suppose we learn that we need 1000 warmup samples and about 9000 real samples\n",
      "in total. Should we run one chain, with warmup=1000 anditer=10000 , or rather 3 chains,\n",
      "with warmup=1000 anditer=4000 ? It doesn’t really matter, in terms of inference.\n",
      "But it might matter in efficiency, because the 3 chains cost you an extra 2000 samples\n",
      "of warmup that just get thrown away. And since warmup is typically the slowest part of the\n",
      "chain, these extra 2000 samples cost a disproportionate amount of your computer’s time.\n",
      "On the other hand, if you run the chains on different computers or processor cores within a\n",
      "single computer, then you might prefer 3 chains, because you can spread the load and finish\n",
      "the whole job faster.\n",
      "There are exotic situations in which all of the advice above must be modified. But for\n",
      "typical regression models, you can live by the motto four short chains to check, one long chain\n",
      "for inference . Things may still go wrong—you’ll see some examples in the next sections, so\n",
      "you know what to look for. And once you know what to look for, you can fix any problems\n",
      "before running a long final Markov chain.\n",
      "One of the perks of using HMC and Stan is that when sampling isn’t working right, it’s\n",
      "usually very obvious. As you’ll see in the sections to follow, bad chains tend to have con-\n",
      "spicuous behavior. Other methods of MCMC sampling, like Gibbs sampling and ordinary\n",
      "Metropolis, aren’t so easy to diagnose.\n",
      "Rethinking: Convergence diagnostics. The default diagnostic output from Stan includes two met-\n",
      "rics, n_effandRhat. The first is a measure of the effective number of samples. The second is the\n",
      "Gelman-Rubin convergence diagnostic, ^R.143When n_effis much lower than the actual number of\n",
      "iterations (minus warmup) of your chains, it means the chains are inefficient, but possibly still okay.\n",
      "When Rhatis above 1.00, it usually indicates that the chain has not yet converged, and probably you\n",
      "shouldn’t trust the samples. If you draw more iterations, it could be fine, or it could never converge.\n",
      "See the Stan user manual for more details. It’s important however not to rely too much on these di-\n",
      "agnostics. Like all heuristics, there are cases in which they provide poor advice. For example, Rhat...\n",
      "\n",
      "Page: 288\n",
      "Text: 9.3. HAMILTONIAN MONTE CARLO 273\n",
      "above, thatwhenthereisarandomwayofaccomplishingsomecalculation, thereisprobably\n",
      "a less random way that is better. This less random way may require a lot more thought. The\n",
      "Gibbs strategy has limitations, but it gets its improvement over plain Metropolis by being\n",
      "less random, not more.\n",
      "HamiltonianMonteCarlo (orHybridMonteCarlo,HMC)pushesJaynes’principle\n",
      "muchfurther. HMCismorecomputationallycostlythanMetropolisorGibbssampling. But\n",
      "itsproposalsarealsomuchmoreefficient. Asaresult,HMCdoesn’tneedasmanysamplesto\n",
      "describe the posterior distribution. You need less computer time in total, even though each\n",
      "sample needs more. And as models become more complex—thousands or tens of thousands\n",
      "ofparameters—HMCcanreallyoutshineotheralgorithms,becausetheotheralgorithmsjust\n",
      "won’t work. The Earth would be swallowed by the Sun before your chain produces a reliable\n",
      "approximation of the posterior.\n",
      "We’re going to be using HMC on and off for the remainder of this book. You won’t\n",
      "have to implement it yourself. But understanding some of the concept behind it will help\n",
      "you grasp how it outperforms Metropolis and Gibbs sampling and also how it encounters its\n",
      "own, unique problems.\n",
      "9.3.1. Another parable. Suppose King Markov’s cousin Monty is King on the mainland.\n",
      "Monty’skingdomisnotadiscretesetofislands. Instead,itisacontinuousterritorystretched\n",
      "out along a narrow valley, running north-south. But the King has a similar obligation: to\n",
      "visit his citizens in proportion to their local population density. Within the valley, people\n",
      "distribute themselves inversely proportional to elevation—most people live in the middle of\n",
      "the valley, fewer up the mountainside. How can King Monty fulfill his royal obligation?\n",
      "Like Markov, Monty doesn’t wish to bother with schedules and calculations. Also like\n",
      "Markov, Monty has a highly educated and mathematically gifted advisor, named Hamilton.\n",
      "Hamilton designed an odd, but highly efficient, method. And this method solves one of\n",
      "Metropolis’ flaws—the king hardly ever stays in the same place, but keeps moving on to visit\n",
      "new locations.\n",
      "Here’showitworks. Theking’svehiclepicksrandomdirection,eithernorthorsouth,and\n",
      "drivesoffatarandommomentum. Asthevehiclegoesuphill,itslowsdownandturnsaround\n",
      "when its declining momentum forces it to. Then it picks up speed again on the way down.\n",
      "Afterafixedperiodoftime,theystopthevehicle,getout,andstartshakinghandsandkissing\n",
      "babies. Then they get back in the vehicle and begin again. Amazingly, Hamilton can prove\n",
      "mathematicallythatthisprocedureguarantees that, in thelongrun, thelocationsvisited will\n",
      "be inversely proportional to their relative elevations, which are also inversely proportional\n",
      "to the population densities. Not only does this keep the king moving, but it also spaces\n",
      "the locations apart better—unlike the other king, Monty does not only visit neighboring\n",
      "locations.\n",
      "This mad plan is illustrated, and simulated, in Figure 9.5. The horizontal axis is time.\n",
      "The vertical axis is location. The king’s journey starts on the far left, in the middle of the\n",
      "valley. Thevehiclebeginsbyheadingsouth. Thewidthofthecurveindicatesthemomentum\n",
      "at each time. The vehicle climbs up hill but slows and briefly turns around before stopping\n",
      "at the first location. Then again and again new locations are chosen in the same way, but\n",
      "with differentrandom directionsand momentums, departing fromthe mostrecentlocation.\n",
      "When the initial momentum is small, the vehicle starts to turn around earlier. But when the\n",
      "initial momentum is large, like in the big swing around time 300, the king can traverse the\n",
      "entire valley before stopping....\n",
      "\n",
      "Answer:  Gibbs sampling is a variant of the Metropolis-Hastings algorithm used for Markov Chain Monte Carlo. It is designed to generate more efficient proposals by using conjugate pairs of prior distributions and likelihoods. However, for complex models with many parameters, Hamiltonian Monte Carlo may be more efficient than Gibbs sampling.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m()\n\u001b[1;32m     15\u001b[0m question \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEnter a question: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m response \u001b[39m=\u001b[39m chain({\u001b[39m\"\u001b[39;49m\u001b[39mquestion\u001b[39;49m\u001b[39m\"\u001b[39;49m: question, \u001b[39m\"\u001b[39;49m\u001b[39mchat_history\u001b[39;49m\u001b[39m\"\u001b[39;49m: chat_history})\n\u001b[1;32m     19\u001b[0m answer \u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39m\u001b[39manswer\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     20\u001b[0m source \u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39m\u001b[39msource_documents\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/langchain/chains/base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/langchain/chains/base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    130\u001b[0m     inputs,\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/langchain/chains/conversational_retrieval/base.py:110\u001b[0m, in \u001b[0;36mBaseConversationalRetrievalChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    108\u001b[0m new_inputs[\u001b[39m\"\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m new_question\n\u001b[1;32m    109\u001b[0m new_inputs[\u001b[39m\"\u001b[39m\u001b[39mchat_history\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m chat_history_str\n\u001b[0;32m--> 110\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_docs_chain\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    111\u001b[0m     input_documents\u001b[39m=\u001b[39;49mdocs, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_inputs\n\u001b[1;32m    112\u001b[0m )\n\u001b[1;32m    113\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_source_documents:\n\u001b[1;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key: answer, \u001b[39m\"\u001b[39m\u001b[39msource_documents\u001b[39m\u001b[39m\"\u001b[39m: docs}\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/langchain/chains/base.py:239\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m], callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    241\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    242\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    243\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m but none were provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    245\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/langchain/chains/base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/langchain/chains/base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    130\u001b[0m     inputs,\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/langchain/chains/combine_documents/base.py:84\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m     83\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[0;32m---> 84\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_docs(\n\u001b[1;32m     85\u001b[0m     docs, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mother_keys\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     87\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n\u001b[1;32m     88\u001b[0m \u001b[39mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/langchain/chains/combine_documents/stuff.py:87\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_inputs(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     86\u001b[0m \u001b[39m# Call predict on the LLM.\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_chain\u001b[39m.\u001b[39;49mpredict(callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs), {}\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/langchain/chains/llm.py:213\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    199\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \n\u001b[1;32m    201\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/langchain/chains/base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/langchain/chains/base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    130\u001b[0m     inputs,\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/langchain/chains/llm.py:69\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[1;32m     65\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     66\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m     67\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     68\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 69\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/langchain/chains/llm.py:79\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[0;32m---> 79\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m     80\u001b[0m     prompts, stop, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m     81\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/langchain/llms/base.py:134\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    128\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    129\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m    130\u001b[0m     stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    131\u001b[0m     callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    132\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    133\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/langchain/llms/base.py:191\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    190\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 191\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    192\u001b[0m run_manager\u001b[39m.\u001b[39mon_llm_end(output)\n\u001b[1;32m    193\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/langchain/llms/base.py:185\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[1;32m    180\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    181\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, prompts, invocation_params\u001b[39m=\u001b[39mparams\n\u001b[1;32m    182\u001b[0m )\n\u001b[1;32m    183\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    184\u001b[0m     output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 185\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(prompts, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    186\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    187\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    190\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/langchain/llms/openai.py:324\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[0;34m(self, prompts, stop, run_manager)\u001b[0m\n\u001b[1;32m    322\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 324\u001b[0m     response \u001b[39m=\u001b[39m completion_with_retry(\u001b[39mself\u001b[39;49m, prompt\u001b[39m=\u001b[39;49m_prompts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    325\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    326\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstreaming:\n\u001b[1;32m    327\u001b[0m     \u001b[39m# Can't update token usage if streaming\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/langchain/llms/openai.py:106\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 106\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/langchain/llms/openai.py:104\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/openai/api_requestor.py:216\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[1;32m    219\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    220\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    221\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    222\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    223\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[1;32m    226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/openai/api_requestor.py:516\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    514\u001b[0m     _thread_context\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m _make_session()\n\u001b[1;32m    515\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 516\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    517\u001b[0m         method,\n\u001b[1;32m    518\u001b[0m         abs_url,\n\u001b[1;32m    519\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    520\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    521\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    522\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    523\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[1;32m    524\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    525\u001b[0m     )\n\u001b[1;32m    526\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    527\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/requests/adapters.py:487\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    484\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    486\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 487\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    488\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    489\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    490\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    491\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    492\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    497\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    498\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    499\u001b[0m     )\n\u001b[1;32m    501\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    502\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1376\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mreadline(_MAXLINE \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1276\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1277\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM_env/lib/python3.11/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def make_chain():\n",
    "    return ConversationalRetrievalChain.from_llm(\n",
    "        model, \n",
    "        new_db.as_retriever(),\n",
    "        return_source_documents=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    load_dotenv()\n",
    "\n",
    "    chain = make_chain()\n",
    "    chat_history = []\n",
    "\n",
    "    while True:\n",
    "        print()\n",
    "        question = input(\"Enter a question: \")\n",
    "\n",
    "        response = chain({\"question\": question, \"chat_history\": chat_history})\n",
    "\n",
    "        answer = response[\"answer\"]\n",
    "        source = response[\"source_documents\"]\n",
    "        chat_history.append(HumanMessage(content=question))\n",
    "        chat_history.append(AIMessage(content=answer))\n",
    "\n",
    "        print(\"/n/nSources:\\n\")\n",
    "        for document in source:\n",
    "            print(f\"Page: {document.metadata['page']}\")\n",
    "            print(f\"Text: {document.page_content}...\\n\")\n",
    "        print(f\"Answer: {answer}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
